---
title: "Testing and Estimation"
subtitle: "for Bayesians, frequentists and agnostics"
format: 
  html: 
    html-math-method: katex
    title-block-banner: "#267326"
    toc: true
    toc-location: left
    callout-icon: false
    other-links:
      - text: GitHub Repository
        icon: github
        href: https://data.nasa.gov/
    code-links:
      - text: Link zum Code
        icon: file-code
        href: index.qmd
author: 
  - name: Samuel Merk
    orcid: 0000-0003-2594-5337
abstract: "Ausgehend von der grundlegenden Unterscheidung deskriptiver, explanativer und explorativer Forschungsfragen, wollen wir einen Blick auch die Gemeinsamkeiten und Unterschiede Bayesesianischer und frequentischer Sch√§tz- und Testmethoden werfen" 
date: today
lang: de
csl: apa.csl
bibliography: references.bib

  
custom-callout:
  customcallout:
    color: "#267326"

filters:
- custom-callout  
- shinylive
  
brand:
  color: 
    link: "#267326"
    background: "#f2f2f2"
typography:
  fonts:
    - family: Source Sans Pro
      source: google
      weight: [300, 400, 600, 700]
      style: [normal, italic]
    - family: Source Serif Pro
      source: google
      weight: [300, 400, 600, 700]
      style: [normal, italic]
    - family: Roboto Mono
      source: google
      # Used for selected high-quality publications (e.g. Festschriften)
  base:
    family: Source Sans Pro
    weight: 400
    size: 16px
    line-height: 1.5
  headings:
    family: Source Sans Pro
    weight: 700
    style: normal
    color: phgruen
    line-height: 1.2
  monospace:
    family: Roboto Mono
    weight: 400
  link:
    weight: 400
    color: phgruen
    decoration: underline
---

## Erkenntnisinteressen

Ganz grundlegend kann a priori das Erkenntnisinteresse von Studien in die folgenden vier Kategorien unterschieden werden:

::: column-page-right
| Deskriptiv | Explorativ | Explanativ | Pr√§diktiv |
|------------------|------------------|------------------|------------------|
| populationsbeschreibend | hypothesengenerierend | hypothesenpr√ºfend | Datenpunkte vorhersagend oder imputierend |
| *Bei welchem Anteil 15-J√§hriger in Deutschland handelt es sich um funktionale Analphabet:innen?* | *Was sind potentielle Ursachen f√ºr genderbezogene Disparit√§ten im Analphabetismus?* | *Sind 15-j√§hrige Jungen h√§ufiger Analphabeten als 15-j√§hrige M√§dchen?* | *Mit welchen Variablen k√∂nnen Sch√ºler:innen at risk erfolgreich identifiziert werden?* |

: Erkenntisinteressen nach [@doering2016].
:::

```{r}
#| echo: false
ifeb_names <- c("Andr√©", "Carolin", "Christian", "Erika", "Eva", "Fabian", "Florian", "Johanna", "Kirstin", "Kristina", "Liene", "Marina", "Max", "Michael", "Nilani", "Sarah", "Theresa", "Cora", "Martin")
not_present <- c("Andr√©")
additions <- character(0)
present <- c(ifeb_names[!ifeb_names %in% not_present], additions)
groups_long <- sample(present, length(present))
```

:::::: {.customcallout collapse="true"}
## üß† Arbeitsauftrag:

**Klassifiziert mit dem zugelosten Partnerin bzw. dem zugelosten Partner f√ºr euch aktuelle/interessante Forschungsfragen als Deskriptiv/Explorativ/Explanativ/Pr√§diktiv**

Die Gruppen:

::::: columns
::: {.column width="50%"}
-   `r paste(groups_long[1:2], collapse = " üíù ")`
-   `r paste(groups_long[3:4], collapse = " üíù ")`
-   `r paste(groups_long[5:6], collapse = " üíù ")`
-   `r paste(groups_long[7:8], collapse = " üíù ")`
-   `r paste(groups_long[9:10], collapse = " üíù ")`
-   `r paste(groups_long[11:12], collapse = " üíù ")`
:::

::: {.column width="50%"}
-   `r paste(groups_long[13:14], collapse = " üíù ")`
-   `r paste(groups_long[15:16], collapse = " üíù ")`
-   `r paste(groups_long[17:18], collapse = " üíù ")`
-   `r paste(groups_long[19:20], collapse = " üíù ")`
-   `r paste(groups_long[21:22], collapse = " üíù ")`
-   `r paste(groups_long[23:24], collapse = " üíù ")`
:::
:::::
::::::

## √úbersicht: Bayesianisches und frequentistisches Sch√§tzen und Testen

Eine sehr heuristische Klassifikation inferenzstatistischer Verfahren stellt die Unterscheidung von statistischer Sch√§tzung und Testung dar:

> (Inferenzstatistische) *Sch√§tzungen* (estimation with quantified uncertainty) treffen anhand von Stichproben Aussagen √ºber Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.

> (Inferenzstatistische) *Hypothesentests* bewerten anhand von Stichprobendaten die G√ºltigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.

Diese beiden Verfahren k√∂nnen sowohl im Rahmen der **frequentistischen Statistik** als auch der **bayesianischen Statistik** angewendet werden. Die folgende Tabelle gibt einen √úberblick √ºber die wichtigsten Werkzeuge:

|   | Frequentistische Statistik | Bayesianische Statistik |
|----------------------|--------------------------|------------------------|
| Parametersch√§tzung | Konfidenzintervalle | Posterior Distributions |
| Hypothesentest | p-Werte & ROPE CI-Procedure | Bayes Faktoren & ROPE-CrI Procedure |

### Hypothesenarten & Informationsgehalt

Bayesianische wie frequentistischen Hypothesentests k√∂nnen unterschiedliche Arten von Hypothesen zugrunde gelegt werden:

-   **Punkthypothesen** setzen Parameter gleich einer reellen Zahl; etwa $H_0\text{: } \delta = 0$
-   **√Ñquivalenzhypothesen** nehmen Parameter in einem reellen Intervall an; etwa $H_0\text{: } \delta \not\in\ [-.3, .3]$
-   **Informative Hypothesen** nehmen eine Ordnungsrelation mehrerer Parameter an; etwa $\mu_{\text{Baseline}} < \mu_{\text{Imaginary Pill}} < \mu_{\text{Blinded Placebo}}$ [@buergler2023]

> **Die *Art* der (falsifizierten) Hypothese entscheidet oft wesentlich st√§rker √ºber den Informationsgehalt eines Hypothesentests als die Entscheidung f√ºr das frequentistische oder bayesianische Paradigma** [@hoijtink2012; @scheel2021].

Dies ist am leichtesten anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese $H_0\text{: } \delta = 0$ verworfen, wird entsprechend die Alternativhypothese $H_A\text{: } \delta \neq 0$ angenommen. Diese enth√§lt aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ...) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enth√§lt, umso leichter sie verworfen werden kann [@doering2016].

√Ñquivalenzhypothesen k√∂nnen sowohl frequentistisch [z.B. TOAST-Prozedur in R und JASP, @lakens2017] wie bayesianisch [z.B. ROPE-Ansatz @kruschke2015] getestet werden. F√ºr das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und R vor [z.B. `{bain}`, @gu2019] sowie in den frequentistischen R-Pakete `{restriktor}` [@vanbrabant2020] und `{ic.infer}` [@gromping2010].

```{r}
#| echo: false
groups_long <- sample(present, length(present))
```

:::::: {.customcallout collapse="true"}
## üß† Arbeitsauftrag:

**Pitched eurer Partnerin bzw. eurem Partner eine Hypothese, die ihr in letzter Zeit getestet habt. Dieser klassifiziert diese dann als Punkthypothese, √Ñquivalenzhypothese oder informative Hypothese**

Die Gruppen:

::::: columns
::: {.column width="50%"}
-   `r paste(groups_long[1:2], collapse = " üíù ")`
-   `r paste(groups_long[3:4], collapse = " üíù ")`
-   `r paste(groups_long[5:6], collapse = " üíù ")`
-   `r paste(groups_long[7:8], collapse = " üíù ")`
-   `r paste(groups_long[9:10], collapse = " üíù ")`
-   `r paste(groups_long[11:12], collapse = " üíù ")`
:::

::: {.column width="50%"}
-   `r paste(groups_long[13:14], collapse = " üíù ")`
-   `r paste(groups_long[15:16], collapse = " üíù ")`
-   `r paste(groups_long[17:18], collapse = " üíù ")`
-   `r paste(groups_long[19:20], collapse = " üíù ")`
-   `r paste(groups_long[21:22], collapse = " üíù ")`
-   `r paste(groups_long[23:24], collapse = " üíù ")`
:::
:::::
::::::

## Frequentistisches Testen

### Was sind *p*-Werte?

In den Sozialwissenschaften sind *p*-Werte das wohl verbreitetste inferenzstatistische Tool. W√§hrend Ronald Fisher [-@fisher1925] die *p*-Werte als graduelles Ma√ü f√ºr die Evidenz gegen eine Nullhypothese (Punkthypothese) entwickelte, kombinierten Jerzy Neyman und Egon Pearson [-@neyman1933] dieses Konzept mit dem von ihnen entwickelten Hypothesentest-Framework ($\alpha$- und $\beta$-Fehler etc.).

::: customcallout
## üí° Definition *p*-Wert

Konzeptuell k√∂nnen *p*-Werte als die bedingte Wahrscheinlichkeit definiert werden, mit der unter der Annahme der G√ºltigkeit der Nullhypothese die vorliegen Daten oder noch extremer gegen die Nullhypothese sprechende Daten beobachtet werden.

$$\text{p-Wert}= P\left(\text{vorl. o. extremer f√ºr }H_A\text{ sprechende Daten} | H_0 \text{ ist wahr}\right)$$
:::

### Beispielhafte *p*-Wert Berechnung

Angenommen wir haben die folgenden Hypothesen & Daten:

-   Hypothesen
    -   Nullhypothese: <br> *Der Anteil der Bef√ºrworter\*innen von G9 (vs G8) = 50%.*
    -   Alternativhypothese: <br> *Mehr als 50% der Eltern bef√ºrworten G9 (vs G8).*
-   Daten:
    -   3 ¬ªf√ºr G9¬´
    -   1 ¬ªf√ºr G8¬´

![](img/BinomBaumG9.svg){.lightbox}

### Typische *p*-Wert-Fehlkonzepte

In der Praxis wird jedoch h√§ufig eine Mischung aus beiden Ans√§tzen verwendet, was zu Missverst√§ndnissen und Fehlinterpretationen f√ºhren kann @greenland2016. z.B.:

-   The P value is the probability that the test hypothesis is true ‚ùå

-   The P value for the null hypothesis is the probability that chance alone produced the observed association ‚ùå

-   A significant test result ($P \leq .05$) means that the test hypothesis is false ‚ùå

-   A nonsignificant test result ($P > .05$) means that the test hypothesis is true or should be accepted ‚ùå

-   A large P value is evidence in favor of the test hypothesis ‚ùå

-   Lack of statistical significance indicates that the effect size is small ‚ùå


```{r}
#| echo: false
groups_long <- sample(present, length(present))
```

:::::: {.customcallout collapse="true"}
## üß† Arbeitsauftrag:

**Welche p-Wert-Fehlkonzepte a) beobachtet ihr am h√§ufigsten b) findet ihr am unverst√§ndlichsten?**

Die Gruppen:

::::: columns
::: {.column width="50%"}
-   `r paste(groups_long[1:2], collapse = " üíù ")`
-   `r paste(groups_long[3:4], collapse = " üíù ")`
-   `r paste(groups_long[5:6], collapse = " üíù ")`
-   `r paste(groups_long[7:8], collapse = " üíù ")`
-   `r paste(groups_long[9:10], collapse = " üíù ")`
-   `r paste(groups_long[11:12], collapse = " üíù ")`
:::

::: {.column width="50%"}
-   `r paste(groups_long[13:14], collapse = " üíù ")`
-   `r paste(groups_long[15:16], collapse = " üíù ")`
-   `r paste(groups_long[17:18], collapse = " üíù ")`
-   `r paste(groups_long[19:20], collapse = " üíù ")`
-   `r paste(groups_long[21:22], collapse = " üíù ")`
-   `r paste(groups_long[23:24], collapse = " üíù ")`
:::
:::::
::::::


## Parametersch√§tzung

### Wahrscheinlichkeitsbegriffe

In der frequentistischen Statistik wird Wahrscheinlichkeit als der Grenzwert der relativen H√§ufigkeit eines Ereignisses in unendlich vielen Wiederholungen eines Zufallsexperiments konzeptualisiert. Demgegen√ºber wird in der bayesianischen Statistik Wahrscheinlichkeit als Ma√ü f√ºr die Sicherheit des eintreten eines Ereignisses verstanden.

| Frequentistisch | Bayesianisch |
|------------------------------------|------------------------------------|
| Eine faire M√ºnze hat eine Wahrscheinlichkeit von 0.5 f√ºr ¬ªKopf¬´, weil bei unendlich vielen W√ºrfen der Anteil der ¬ªKopf¬´-W√ºrfe gegen 50% konvergiert. | Eine faire M√ºnze hat eine Wahrscheinlichkeit von 0.5 f√ºr ¬ªKopf¬´, weil 0,5 die Mitte zwischen ¬ªvollkommen sicher Kopf¬´ und ¬ªvollkommen sicher Zahl¬´ ist. |
| ![](img/FWkeit.svg) | ![](img/BWkeit.svg) |

: Wahrscheinlichkeitsbegriffe

Aus diesen unterschiedlichen Wahrscheinlichkeitsbegriffen ergeben sich in der frequentistischen und bayesianischen Statistik unterschiedliche Interpretationen von Unsicherheiten in der Parametersch√§tzung die oft als Konfidenzintervalle (frequentistisch) bzw. Credibility Intervalle (bayesianisch) operationalisiert werden.

### Bayesianische Parametersch√§tzung (Credibility Intervalle)
Credibilityintervalle werden dann aus dieser Posteriorverteilung abgeleitet.
Um Parameter eines statistischen Modells (z.B. Intercept und Slope in einer Regressionsanalyse, Anteil $\theta$ an G9 Bef√ºrworter:innen) zu sch√§tzen, wird im bayesianischen Paradigma die a priori Annahme √ºber die Verteilung des Parameters (Prior) mit den vorliegenden Daten (Likelihood) kombiniert, um via des Satz von Bayes eine a posteriori Verteilung des Parameters (Posterior) zu erhalten. Aus dieser l√§sst sich dann sowohl die Punktsch√§tzung (z.B. ¬ªMaximum a Postiori¬´), als auch dessen Unsicherheit (z.B. ¬ªHighest Density Intervals¬´) ableiten.

::: customcallout
## üí° Satz von Bayes
$$\text{Posterior}=\frac{\text{Likelihood} \times \text{Prior}}{\text{Evidenz}}$$

$$P(\theta \mid d)=\frac{p(d \mid \theta) \cdot P(\theta)}{P(d)}$$
:::

Credibilityintervalle um Parameterpunktsch√§tzungen enthalten entlang der bayesianischen Wahrscheinlichkeitsdefinition Aussagen dar√ºber, mit welcher Wahrscheinlichkeit der wahre Parameterwert in einem bestimmten Intervall liegt. 

::: column-page-right

```{=html}
<iframe width="100%" height="875" src="app2.html" title="Quarto Documentation"></iframe>
```
:::


```{r}
#| echo: false
groups_long <- sample(present, length(present))
```

:::::: {.customcallout collapse="true"}
## üß† Arbeitsauftrag:

1) Beobachtet in der App wie die Pr√§zision des Priors (bei konstantem Mittelwert) den Posterior beinflusst.
2) Beobachtet in der App wie recht stark vom Prior divergierende Daten den Posterior beinflussen wenn die Datenmenge sehr gro√ü wird.

Die Gruppen:

::::: columns
::: {.column width="50%"}
-   `r paste(groups_long[1:2], collapse = " üíù ")`
-   `r paste(groups_long[3:4], collapse = " üíù ")`
-   `r paste(groups_long[5:6], collapse = " üíù ")`
-   `r paste(groups_long[7:8], collapse = " üíù ")`
-   `r paste(groups_long[9:10], collapse = " üíù ")`
-   `r paste(groups_long[11:12], collapse = " üíù ")`
:::

::: {.column width="50%"}
-   `r paste(groups_long[13:14], collapse = " üíù ")`
-   `r paste(groups_long[15:16], collapse = " üíù ")`
-   `r paste(groups_long[17:18], collapse = " üíù ")`
-   `r paste(groups_long[19:20], collapse = " üíù ")`
-   `r paste(groups_long[21:22], collapse = " üíù ")`
-   `r paste(groups_long[23:24], collapse = " üíù ")`
:::
:::::
::::::



### Frequentistische Parametersch√§tzung (Konfidenzintervalle)

Konfidenzintervalle um Parameterpunktsch√§tzungen enthalten entlang der frequentistischen Wahrscheinlichkeitsdefinition Aussagen dar√ºber, welcher Anteil von Konfidenzintervallen (in the long run) den wahren Parameterwert enth√§lt. 

![Animation von https://rpsychologist.com/d3/ci/](img/CI2.gif)

## Die ROPE-Testing-Prozedur

Sowohl Credibilityintervalle als auch Konfidenzintervalle k√∂nnen genutzt werden, um √Ñquivalenzhypothesen zu testen. Hierzu wird ein sogenanntes ROPE (Region of Practical Equivalence) definiert, das den Bereich von Parameterwerten beschreibt, die als praktisch √§quivalent zur Nullhypothese angesehen werden (z.B. Bev√∂lkerung ist ¬ªquasi unentschieden so lange $.47 < \theta_{pro\,G9} < .53$)¬´. Die Lage des Credibility- bzw. Konfidenzintervalls in Bezug auf das ROPE entscheidet dann √ºber die Evidenz f√ºr oder gegen die √Ñquivalenznullhypothese:

| Lage                                   | Testentscheidung |
|----------------------------------------|------------------|
| CI bzw. CrI vollst√§ndig innerhalb ROPE | $H_0$ annehmen   |
| CI bzw. CrI vollst√§ndig au√üerhalb ROPE | $H_1$ annehmen   |
| sonst                                  | inkonklusiv      |

: ROPE-Testprozedur



## Bayes Faktoren

Bayes Faktoren sind ein zentrales Werkzeug der bayesianischen Statistik zur Bewertung von Hypothesen anhand von Daten. Sie quantifizieren die relative Evidenz, die die Daten f√ºr eine Hypothese im Vergleich zu einer anderen Hypothese liefern. Ausgangspunkt ist dabei das Bayes Theorem, das zwei eine bedingte Wahrscheinlichkeit eines datengenerierenden Modells $\mathscr{M}_1$ gegeben Daten $d$ mit der umgekehrten bedingten Wahrscheinlichkeit der Daten gegeben dem Modell relationiert:

$$P\left(\mathscr{M}_1 \mid d\right)=\frac{p\left(d \mid \mathscr{M}_1\right) P\left(\mathscr{M}_1\right)}{P(d)}$$

Wendet man dieses Theorem auf ein konkurrierendes Modelle $\mathscr{M}_1$ an und betrachtet die posterior Odds $\frac{P\left(\mathscr{M}_1 \mid d\right)}{P\left(\mathscr{M}_0 \mid d\right)}$, so erh√§lt man die Definition des Bayes Faktors $BF_{10}$:

::: customcallout
## üí° Definition Bayes Faktor

Konzeptuell k√∂nnen Bayes Faktoren als das Verh√§ltnis der Wahrscheinlichkeit der vorliegenden Daten unter zwei konkurrierenden Modellen definiert werden:

$$
\underbrace{\frac{P\left(\mathscr{M}_1 \mid d\right)}{P\left(\mathscr{M}_0 \mid d\right)}}_{\text {Posterior odds }}=\underbrace{\frac{p\left(d \mid \mathscr{M}_1\right)}{p\left(d \mid \mathscr{M}_0\right)}}_{\mathrm{BF}_{10}(d)} \underbrace{\frac{P\left(\mathscr{M}_1\right)}{P\left(\mathscr{M}_0\right)}}_{\text {Prior odds }}
$$
:::

Er heisst also ¬ªFaktor¬´, weil er multipliziert mit den a priori zu bestimmenden Prior odds multipliziert, die posterior odds ergibt. Der Bayes Faktor quantifiziert also, wie stark die Daten die a priori relative Plausibilit√§t zweier Modelle ver√§ndern/updaten.

### Beispielhafte Bayes-Faktor-Berechnung

Besonders einfach sind Bayes Faktoren f√ºr Punkthypothesen zu berechnen. Wichtig ist dabei, dass ¬ªHypothese¬´ und ¬ªdatengenerierendes Modell¬´ hier oft synonym verwendet werden.

:::: column-page-right
::: customcallout
## Beispiel

Angenommen zwei Bildungspolitiker:innen streiten sich √ºber die Verbreitung der Elternmeinung zur Bef√ºrwortung von G8 vs. G9. Die eine Politikerin behauptet, dass 40% der Eltern G9 bef√ºrworten, die andere Politikerin behauptet, dass 60% der Eltern G9 bef√ºrworten. In einer ¬ªStudie¬´ wurden 10 Proband:innen befragt und genau 8 davon waren pro G9, 2 pro G8. In der interaktiven App unten repr√§sentiert der Quotion der vertikalen [orangenen]{style="color: #d77;"} und [gr√ºnen]{style="color: #267326;"} Strecken den Bayes Faktor.

```{=html}
<iframe width="100%" height="900" src="app.html" title="Bayes factor App 1"></iframe>
```
:::
::::

### Bayesfaktoren mit a priori Verteilungshypothesen

Die zuvor gemachten Hypothesen (Punkthypothesen: ¬ªgenau 40%¬´ bzw. ¬ªgenau 60%¬´) sind in der Praxis eher selten bzw. unn√ºtz. Wesentlich realistischer ist es a priori Hypothesen/Modelle anzunehmen, die verschiedenen Prozents√§tzen verschiedene Plausibilit√§t zuordnen (siehe folgende interaktive App oben). Dies kann durch die Angabe von Wahrscheinlichkeitsverteilungen (z.B. Beta-Verteilungen im Fall von Anteilen) erfolgen. Das Problem ist nun, dass man den Bayes Faktor nicht mehr wie zuvor berechnen kann, weil man ja keinen festen Wert/Prozentsatz f√ºr die Hypothese hat - man wei√ü nicht ¬ªwelche Wahrscheinlichkeit man an das B√§umchen schreiben soll¬´. Harold Jeffreys [-@jeffreys1998theory] geniale L√∂sung hierf√ºr ist es, die Wahrscheinlichkeit der Daten f√ºr jeden Anteil der G9-Bef√ºrworter:innen $\theta$ zu berechnen und diese dann gewichtet nach der a priori Verteilungshypothese zu mitteln:

$$
\frac{p\left(d \mid \mathscr{M}_1\right)}{p\left(d \mid \mathscr{M}_2\right)} = \frac{p\left(d \mid \mathscr{M}_1\right)=\int f\left(d \mid \theta_1, \mathscr{M}_1\right)  \cdot \pi_1\left(\theta_1\right) \; \mathrm{d} \theta_1}{p\left(d \mid \mathscr{M}_2\right)=\int f\left(d \mid \theta_2, \mathscr{M}_2\right) \cdot \pi_2\left(\theta_2\right) \; \mathrm{d} \theta_2}
$$

::: column-page-right
```{=html}
<iframe width="100%" height="900" src="app3.html" title="Bayes factor App 1"></iframe>
```
:::


## Literatur