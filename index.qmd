---
title: "Testing and Estimation"
subtitle: "for Bayesians, frequentists and agnostics"
format: 
  html: 
    title-block-banner: "#267326"
    toc: true
    toc-location: left
    code-link: true
    code-links: true
author: 
  - name: Samuel Merk
    orcid: 0000-0003-2594-5337
abstract: "Ausgehend von der grundlegenden Unterscheidung deskriptiver, explanativer und explorativer Forschungsfragen, wollen wir einen Blick auch die Gemeinsamkeiten und Unterschiede Bayesesianischer und frequentischer Schätz- und Testmethoden werfen" 
date: today
lang: de
csl: apa.csl
bibliography: references.bib
filters:
  - shinylive
  
  
brand:
  color: 
    link: "#267326"
    background: "#f2f2f2"
typography:
  fonts:
    - family: Source Sans Pro
      source: google
      weight: [300, 400, 600, 700]
      style: [normal, italic]
    - family: Source Serif Pro
      source: google
      weight: [300, 400, 600, 700]
      style: [normal, italic]
    - family: Roboto Mono
      source: google
      # Used for selected high-quality publications (e.g. Festschriften)
  base:
    family: Source Sans Pro
    weight: 400
    size: 16px
    line-height: 1.5
  headings:
    family: Source Sans Pro
    weight: 700
    style: normal
    color: phgruen
    line-height: 1.2
  monospace:
    family: Roboto Mono
    weight: 400
  link:
    weight: 400
    color: phgruen
    decoration: underline
---

## Erkenntnisinteressen

Ganz grundlegend kann a priori das Erkenntnisinteresse von Studien in die folgenden vier Kategorien unterschieden werden:

::: column-page-right
| Deskriptiv | Explorativ | Explanativ | Prädiktiv |
|------------------|------------------|------------------|------------------|
| populationsbeschreibend | hypothesengenerierend | hypothesenprüfend | Datenpunkte vorhersagend oder imputierend |
| *Bei welchem Anteil 15-Jähriger in Deutschland handelt es sich um funktionale Analphabet:innen?* | *Was sind potentielle Ursachen für genderbezogene Disparitäten im Analphabetismus?* | *Sind 15-jährige Jungen häufiger Analphabeten als 15-jährige Mädchen?* | *Mit welchen Variablen können Schüler:innen at risk erfolgreich identifiziert werden?* |

: Erkenntisinteressen nach [@doering2016].
:::

## Gütekriterien wiss. Erkenntnis nach @campbell1957

Für ein erfolgreiches Studiendesign und die anschließende statistische Analyse ist es sehr wertvoll sich vorab über Schwerpunkte besonders gewünschter Aspekte wissenschaftlicher Güte Gedanken zu machen. Insbesondere über die Unterkriterien **Methodischer Strenge**:

-   **Konstruktvalidität** (*Inwiefern ist die Interpretation der Messwerte angemessen?*)
-   **Interne Validität** (*Inwiefern sind Assoziationen von unabhängiger \[beeinflussender\] und abhängiger \[beeinflusster\] Variabler als kausale Effekte interpretierbar?*)
-   **Externe Validität** (*Inwiefern können die Schlussfolgerungen der Studie verallgemeinert werden?*)
-   **Statistische Validität** (*Wie robust und angemessen sind die verwendeten statistischen Verfahren?*)

## Deskriptiv- und Inferenzstatistik

**Deskriptive Statistik** beschreibt vorliegende Daten (z.B. mit Effektstärken), während **Inferenzstatistik** Aussagen über den die Daten generierenden Mechanismus trifft. Beide können »eher einfach« oder »hoch komplex« sein und oftmals stehen sie in einem synergetischen Verhältnis (siehe @fig-jingjang).

::: column-margin
![Synergetisches Verhältnis von deskriptiver Statistik und Inferenzstatistik](img/yingyang.svg){#fig-jingjang width="300px"}
:::

## Bayesianisches und Frequentistisches Schätzen und Testen

Eine sehr heuristische Klassifikation inferenzstatistischer Verfahren stellt die Unterscheidung von statistischer Schätzung und Testung dar:

> (Inferenzstatistische) *Schätzungen* (estimation with quantified uncertainty) treffen anhand von Stichproben Aussagen über Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.[^1]

[^1]: Bspw.: *»Mit 96%iger Wahrscheinlichkeit liegt die Analphabetismusinzidienz von 15-Jährigen in Deutschland zwischen .08 und .12«*

> (Inferenzstatistische) *Hypothesentests* bewerten anhand von Stichprobendaten die Gültigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.[^2]

[^2]: Bspw.: *»Nimmt man an, dass sich die Analphabetismusinzidienz von 15-Jährigen in Deutschland zwischen 2021 und 2025 nicht geändert hat, beträgt die Wahrscheinlichkeit der vorliegenden Daten p = .032«*

Diese beiden Verfahren können sowohl im Rahmen der **frequentistischen Statistik** als auch der **bayesianischen Statistik** angewendet werden. Die folgende Tabelle gibt einen Überblick über die wichtigsten Werkzeuge:

|   | Frequentistische Statistik | Bayesianische Statistik |
|----------------------|--------------------------|------------------------|
| Parameterschätzung | Konfidenzintervalle | Posterior Distributions |
| Hypothesentest | p-Werte | Bayes Faktoren & ROPE-CrI Procedure |

## Hypothesenarten

Bayesianische wie frequentistischen Hypothesentests können unterschiedliche Arten von Hypothesen zugrunde gelegt werden:

-   **Punkthypothesen** setzen Parameter gleich einer reellen Zahl; etwa $H_0\text{: } \delta = 0$
-   **Äquivalenzhypothesen** nehmen Parameter in einem reellen Intervall an; etwa $H_0\text{: } \delta \not\in\ [-.3, .3]$
-   **Informative Hypothesen** nehmen eine Ordnungsrelation mehrerer Parameter an; etwa $\mu_{\text{Baseline}} < \mu_{\text{Imaginary Pill}} < \mu_{\text{Blinded Placebo}}$ [@buergler2023]

> **Die *Art* der (falsifizierten) Hypothese entscheidet oft wesentlich stärker über den Informationsgehalt eines Hypothesentests als die Entscheidung für das frequentistische oder bayesianische Paradigma** [@hoijtink2012; @scheel2021].

Dies ist am leichtesten anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese $H_0\text{: } \delta = 0$ verworfen, wird entsprechend die Alternativhypothese $H_A\text{: } \delta \neq 0$ angenommen. Diese enthält aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ...) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enthält, umso leichter sie verworfen werden kann [@doering2016].

Äquivalenzhypothesen können sowohl frequentistisch [z.B. TOAST-Prozedur in R und JASP, @lakens2017] wie bayesianisch [z.B. ROPE-Ansatz @kruschke2015] getestet werden. Für das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und R vor [z.B. `{bain}`, @gu2019] sowie in den frequentistischen R-Pakete `{restriktor}` [@vanbrabant2020] und `{ic.infer}` [@gromping2010].

## Shinylive

::: column-page-right
```{shinylive-r}
#| standalone: true
#| viewerHeight: 800

library(bslib)
library(shiny)
library(ggplot2)
library(tibble)
library(dplyr)
library(munsell)
library(shinyjs)

ui <- page_fluid(
  theme = bs_theme(
    "bg-primary" = "#1bbc9d50",
    # Controls the accent (e.g., hyperlink, button, etc) colors
    primary = "#267326",
    secondary = "#267326",
    "input-border-color" = "#267326"
  ),
  h5(""),
    layout_column_wrap(
  card(
      card_header(class = "bg-primary", "Punkthypothesen"),
      card_body(
        sliderInput(
          "theta1",
          "Hypothese 1: Anteil Pro G9",
          min = 0,
          max = 1,
          value = .4,
          step = .1
        ),
        sliderInput(
          "theta2",
          "Hypothese 2: Anteil Pro G9",
          min = 0,
          max = 1,
          value = .6,
          step = .1
        )
      )
    ),
    card(
      card_header(class = "bg-primary", "Daten"),
      card_body(
        numericInput(
          "prog9",
          "n₁ = Befürwortung G9",
          min = 0,
          value = 10,
          step = 1
        ),
        numericInput(
          "prog8",
          "n₂ = Befürwortung G8",
          min = 0,
          value = 5,
          step = 1
        )
      )
    )
  ),
  card(
    card_header("Likelihoods und Bayes Factor", class = "bg-primary"),
    #card_body(shinycssloaders::withSpinner(
    plotOutput("plot"),
    #  color = "#267326"
    #))
  )
)


server <- function(input, output, session) {
  # n <- 30 # N()
  # obs <- 20 input$prog9
  # theta1 <- .5 # input$theta1
  # theta2 <- .7 # input$theta2
  # wkeit1 <- choose(n, obs)*theta1^obs*(1-theta1)^(n-obs) # wkeit1()
  # wkeit2 <- choose(n, obs)*theta2^obs*(1-theta2)^(n-obs) # wkeit2()

  ### custom reactive values #####################################################
  N <- reactive({
    input$prog8 + input$prog9
  })

  wkeit1 <-
    reactive({
      choose(N(), input$prog9) *
        input$theta1^input$prog9 *
        (1 - input$theta1)^(N() - input$prog9)
    })

  wkeit2 <-
    reactive({
      choose(N(), input$prog9) *
        input$theta2^input$prog9 *
        (1 - input$theta2)^(N() - input$prog9)
    })

  ### create data ################################################################
  data <- reactive({
    return(
      rbind(
        tibble(
          k = 1:N(),
          p = choose(N(), k) * input$theta1^k * (1 - input$theta1)^(N() - k),
          theta = as.character(input$theta1)
        ),
        tibble(
          k = 1:N(),
          p = choose(N(), k) * input$theta2^k * (1 - input$theta2)^(N() - k),
          theta = as.character(input$theta2)
        )
      ) %>%
        mutate(obs_eq_k = k == N()) %>%
        as_tibble()
    )
  })

  ### plot #######################################################################
  output$plot <- renderPlot({
    ggplot() +
      # add whole binomial distributions with alpha
      geom_segment(
        data = data() %>%
          filter(theta == input$theta1),
        aes(x = k - .1, xend = k - .1, y = 0, yend = p),
        color = "#26732650",
        linewidth = 2
      ) +
      geom_segment(
        data = data() %>%
          filter(theta == input$theta2),
        aes(x = k + .1, xend = k + .1, y = 0, yend = p),
        color = "#d77d0050",
        linewidth = 2
      ) +
      # add selected binomial distributions without alpha
      geom_segment(
        data = data() %>%
          filter(theta == input$theta1 & k == input$prog9),
        aes(x = k - .1, xend = k - .1, y = 0, yend = p, color = "#267326"),
        linewidth = 2
      ) +
      geom_segment(
        data = data() %>%
          filter(theta == input$theta2 & k == input$prog9),
        aes(x = k + .1, xend = k + .1, y = 0, yend = p, color = "#d77d00"),
        linewidth = 2
      ) +
      theme_minimal() +
      geom_text(
        data = tibble(
          x = input$prog9,
          y = -.005,
          text = paste(
            "BF =",
            formatC(wkeit1() / wkeit2(), format = "e", digits = 2)
          )
        ),
        aes(x, y, label = text)
      ) +
      xlab("Anzahl") +
      ylab("Wahrscheinlichkeit") +
      ggtitle("Berechnung des Bayes-Faktors", "bei Punkthypothesen") +
      scale_color_identity(
        name = "Likelihood",
        breaks = c("#bc991b", "#bc1b9a"),
        labels = c("Hyp. 1", "Hyp 2."),
        guide = "legend"
      )
  })

  ### debug ######################################################################
  output$debug <- renderPrint({
    data()
  })
}

shinyApp(ui = ui, server = server)
```
:::